### [Process and translate text with Azure AI Services](https://learn.microsoft.com/en-us/training/paths/process-translate-text-azure-cognitive-services/)

## [Extract insights from text with the Azure AI Language service](https://learn.microsoft.com/en-us/training/modules/extract-insights-text-with-text-analytics-service/)

### Provision an Azure AI Language resource
  * The Azure AI Language service is designed to help you extract information from text. It provides functionality that you can use for:
    1. Language detection - determining the language in which text is written.
    1. Key phrase extraction - identifying important words and phrases in the text that indicate the main points.
    1. Sentiment analysis - quantifying how positive or negative the text is.
    1. Named entity recognition - detecting references to entities, including people, locations, time periods, organizations, and more.
    1. Entity linking - identifying specific entities by providing reference links to Wikipedia articles.
  * <img src="https://learn.microsoft.com/en-us/training/wwl-data-ai/extract-insights-text-with-text-analytics-service/media/text-analytics-resource.png" height=100 width=100>  

### Detect language
* The Azure AI Language Detection API evaluates text input and, for each document submitted, returns language identifiers with a score indicating the strength of the analysis. 
* The Azure AI Language service recognizes up to 120 languages.
* Another scenario could involve a chat bot - Language detection can be used to determine which language they are using and allow you to configure your bot responses in the appropriate language.
* Language detection can work with documents or single phrases. 
* the document size must be under 5,120 characters. The size limit is per document and each collection is restricted to 1,000 items (IDs). 
* A sample JSON, including a collection of documents, each containing a unique id and the text to be analyzed. Optionally, you can provide a countryHint to improve prediction performance.

```
{
  "documents": [
    {
      "countryHint": "US",
      "id": "1",
      "text": "Hello world"
    },
    {
      "id": "2",
      "text": "Bonjour tout le monde"
    }
  ]
}
```
* Parse the JSON response to determine which language is used. The confidence score (0 to 1), with 1 being a higher confidence level. 
```
{
  "documents": [
   {
     "id": "1",
     "detectedLanguage": {
       "name": "English",
       "iso6391Name": "en",
       "confidenceScore": 1
     },
     "warnings": []
   },
   {
     "id": "2",
     "detectedLanguage": {
       "name": "French",
       "iso6391Name": "fr",
       "confidenceScore": 1
     },
     "warnings": []
   }
  ],
  "errors": [],
  "modelVersion": "2020-04-01"
}
```
* If you pass in a document that has multilingual content, the service will behave a bit differently. 
* Mixed language content within the same document returns the language with the largest representation in the content, but with a lower positive rating, reflecting the marginal strength of that assessment. 
* Example, the input is a blend of English, Spanish, and French. The analyzer uses statistical analysis of the text to determine the predominant language.
````
{
  "documents": [
    {
      "id": "1",
      "text": "Hello, I would like to take a class at your University. ¿Se ofrecen clases en español? Es mi primera lengua y más fácil para escribir. Que diriez-vous des cours en français?"
    }
  ]
}

{
  "documents": [
    {
      "id": "1",
      "detectedLanguages": [
        {
          "name": "Spanish",
          "iso6391Name": "es",
          "score": 0.9375
        }
      ]
    }
  ],
  "errors": []
}

* The last condition to consider is when there is ambiguity as to the language content. 
* The scenario might happen if you submit textual content that the analyzer is not able to parse, for example because of character encoding issues when converting the text to a string variable. 
* As a result, the response for the language name and ISO code will indicate (unknown) and the score value will be returned as NaN, or Not a Number. 
* Example
```
{
      "id": "5",
      "detectedLanguages": [
        {
          "name": "(Unknown)",
          "iso6391Name": "(Unknown)",
          "score": "NaN"
        }
      ]
}
```

### Extract key phrases
* Key phrase extraction is the process of evaluating the text of a document, or documents, and then identifying the main points around the context of the document(s).
* Key phrase extraction works best for larger documents (the maximum size that can be analyzed is 5,120 characters).
* As with language detection, the REST interface enables you to submit one or more documents for analysis.
```
{
  "documents": [
    {
      "id": "1",
      "language": "en",
      "text": "You must be the change you wish 
               to see in the world."
    },
    {
      "id": "2",
      "language": "en",
      "text": "The journey of a thousand miles 
               begins with a single step."
    }
  ]
}

* The response contains a list of key phrases detected in each document.
```
{
  "documents": [
   {
     "id": "1",
     "keyPhrases": [
       "change",
       "world"
     ],
     "warnings": []
   },
   {
     "id": "2",
     "keyPhrases": [
       "miles",
       "single step",
       "journey"
     ],
     "warnings": []
   }
  ],
  "errors": [],
  "modelVersion": "2020-04-01"
}
```

### Analyze sentiment
* Sentiment analysis is used to evaluate how positive or negative a text document is, which can be useful in various workloads, such as:
  1. Evaluating a movie, book, or product by quantifying sentiment based on reviews.
  1. Prioritizing customer service responses to correspondence received through email or social media messaging.
* When using the Azure AI Language service to evaluate sentiment, the response includes overall document sentiment and individual sentence sentiment for each document submitted to the service.
* Example, a single document for sentiment analysis
```
{
  "documents": [
    {
      "language": "en",
      "id": "1",
      "text": "Smile! Life is good!"
    }
  ]
}
{
  "documents": [
   {
     "id": "1",
     "sentiment": "positive",
     "confidenceScores": {
       "positive": 0.99,
       "neutral": 0.01,
       "negative": 0.00
     },
     "sentences": [
       {
         "text": "Smile!",
         "sentiment": "positive",
         "confidenceScores": {   
             "positive": 0.97,
	         "neutral": 0.02, 
             "negative": 0.01
           },
         "offset": 0,
         "length": 6
       },
       {
	      "text": "Life is good!",
          "sentiment": "positive",
          "confidenceScores": {   
             "positive": 0.98,
	         "neutral": 0.02,  
             "negative": 0.00
           },
         "offset": 7,
         "length": 13
       }
     ],
     "warnings": []
   }
  ],
  "errors": [],
  "modelVersion": "2020-04-01"
}
```
* Sentence sentiment is based on confidence scores for positive, negative, and neutral classification values between 0 and 1.
* Overall document sentiment is based on sentences:
 1. If all sentences are neutral, the overall sentiment is neutral.
 1. If sentence classifications include only positive and neutral, the overall sentiment is positive.
 1. If the sentence classifications include only negative and neutral, the overall sentiment is negative.
 1. If the sentence classifications include positive and negative, the overall sentiment is mixed.

### Extract entities
* Named Entity Recognition identifies entities that are mentioned in the text. 
* Entities are grouped into categories and subcategories, for example: Person, Location, DateTime, Organization, Address, Email, URL
* Input for entity recognition is similar to input for other Azure AI Language API functions:
```
{
  "documents": [
    {
      "language": "en",
      "id": "1",
      "text": "Joe went to London on Saturday"
    }
  ]
}
{
  "documents":[
      {
          "id":"1",
          "entities":[
          {
            "text":"Joe",
            "category":"Person",
            "offset":0,
            "length":3,
            "confidenceScore":0.62
          },
          {
            "text":"London",
            "category":"Location",
            "subcategory":"GPE",
            "offset":12,
            "length":6,
            "confidenceScore":0.88
          },
          {
            "text":"Saturday",
            "category":"DateTime",
            "subcategory":"Date",
            "offset":22,
            "length":8,
            "confidenceScore":0.8
          }
        ],
        "warnings":[]
      }
  ],
  "errors":[],
  "modelVersion":"2021-01-15"
}
```

### Extract linked entities
* In some cases, the same name might be applicable to more than one entity. 
* For example, does an instance of the word "Venus" refer to the planet or the goddess from mythology?
* Entity linking can be used to disambiguate entities of the same name by referencing an article in a knowledge base. 
* Wikipedia provides the knowledge base for the Text Analytics service. 
* Specific article links are determined based on entity context within the text.
* For example, "I saw Venus shining in the sky" is associated with the link https://en.wikipedia.org/wiki/Venus; 
* while "Venus, the goddess of beauty" is associated with https://en.wikipedia.org/wiki/Venus_(mythology).
```
{
  "documents": [
    {
      "language": "en",
      "id": "1",
      "text": "I saw Venus shining in the sky"
    }
  ]
}
{
  "documents":
    [
      {
        "id":"1",
        "entities":[
          {
            "name":"Venus",
            "matches":[
              {
                "text":"Venus",
                "offset":6,
                "length":5,
                "confidenceScore":0.01
              }
            ],
            "language":"en",
            "id":"Venus",
            "url":"https://en.wikipedia.org/wiki/Venus",
            "dataSource":"Wikipedia"
          }
        ],
        "warnings":[]
      }
    ],
  "errors":[],
  "modelVersion":"2020-02-01"
}
```
### Exercise - Analyze Text
* Example, Process hotel reviews. By using the Azure AI Language, they can determine the language each review is written in, the sentiment (positive, neutral, or negative) of the reviews, key phrases that might indicate the main topics discussed in the review, and named entities, such as places, landmarks, or people mentioned in the reviews.
* Provision an Azure AI Language resource : Azure Portal -> Azure AI services -> Create Language Service.
* Clone the repository for this course in Cloud Shell
 1. Portal > [>_] (Cloud Shell) button  -> Uss Bash (Bash or PowerShell) -> Create storage (if not)
 1. Once the terminal starts -> command to download the sample application and save it to a folder called azure-ai-eng.
  ```
  rm -r azure-ai-eng -f
  git clone https://github.com/MicrosoftLearning/AI-102-AIEngineer azure-ai-eng
  ```
The files are downloaded to a folder named azure-ai-eng. Navigate to the lab files for this exercise using the following command.

Code
cd azure-ai-eng/05-analyze-text
Applications for both C# and Python have been provided, as well as a supporting files you’ll use to test the feature. Both apps feature the same functionality. Navigate to the folder of your preferred language.

Open the built-in code editor, and observe the text files in the text-analysis folder. Use the following command to open the lab files in the code editor.

Code
code .
Prepare to use the Azure AI Language SDK for text analytics
In this exercise, you’ll complete a partially implemented client application that uses the Azure AI Language text analytics SDK to analyze hotel reviews.

[!NOTE]

You can choose to use the SDK for either C# or Python. In the steps below, perform the actions appropriate for your preferred language.

In Cloud Shell, ensure you are in the 05-analyze-text folder and have navigated to the C-Sharp or Python folder depending on your language preference.
Install the Text Analytics SDK package by running the appropriate command for your language preference:

C#

Code
 dotnet add package Azure.AI.TextAnalytics --version 5.3.0
Python

Code
 pip install azure-ai-textanalytics==5.3.0
 pip install python-dotenv
View the contents of the text-analysis folder in the code window, and note that it contains a file for configuration settings:
C#: appsettings.json
Python: .env
Open the configuration file and update the configuration values it contains to reflect the endpoint and an authentication key for your Azure AI Language service resource. Save your changes.

Note that the text-analysis folder contains a code file for the client application:

C#: Program.cs
Python: text-analysis.py
Open the code file and at the top, under the existing namespace references, find the comment Import namespaces. Then, under this comment, add the following language-specific code to import the namespaces you will need to use the Text Analytics SDK:

C#

C#
 // import namespaces
 using Azure;
 using Azure.AI.TextAnalytics;
Python

Code
 # import namespaces
 from azure.core.credentials import AzureKeyCredential
 from azure.ai.textanalytics import TextAnalyticsClient
In the Main function, note that code to load the Azure AI Language service endpoint and key from the configuration file has already been provided. Then find the comment Create client using endpoint and key, and add the following code to create a client for the Text Analysis API:

C#

Code
 // Create client using endpoint and key
 AzureKeyCredential credentials = new AzureKeyCredential(cogSvcKey);
 Uri endpoint = new Uri(cogSvcEndpoint);
 TextAnalyticsClient CogClient = new TextAnalyticsClient(endpoint, credentials);
Python

Code
 # Create client using endpoint and key
 credential = AzureKeyCredential(cog_key)
 cog_client = TextAnalyticsClient(endpoint=cog_endpoint, credential=credential)
Save your changes and return to the integrated terminal for the text-analysis folder, and enter the following command to run the program:

C#

Code
 dotnet run
Python

Code
 python text-analysis.py
Observe the output as the code should run without error, displaying the contents of each review text file in the reviews folder. The application successfully creates a client for the Text Analytics API but doesn’t make use of it. We’ll fix that in the next procedure.
Detect language
Now that you have created a client for the API, let’s use it to detect the language in which each review is written.

In the Main function for your program, find the comment Get language. Then, under this comment, add the code necessary to detect the language in each review document:

C#

C#
 // Get language
 DetectedLanguage detectedLanguage = CogClient.DetectLanguage(text);
 Console.WriteLine($"\nLanguage: {detectedLanguage.Name}");
Python

Code
 # Get language
 detectedLanguage = cog_client.detect_language(documents=[text])[0]
 print('\nLanguage: {}'.format(detectedLanguage.primary_language.name))
Note: In this example, each review is analyzed individually, resulting in a separate call to the service for each file. An alternative approach is to create a collection of documents and pass them to the service in a single call. In both approaches, the response from the service consists of a collection of documents; which is why in the Python code above, the index of the first (and only) document in the response ([0]) is specified.

Save your changes and return to the integrated terminal for the text-analysis folder, and enter the following command to run the program:

C#

Code
 dotnet run
Python

Code
 python text-analysis.py
Observe the output, noting that this time the language for each review is identified.

Evaluate sentiment
Sentiment analysis is a commonly used technique to classify text as positive or negative (or possible neutral or mixed). It’s commonly used to analyze social media posts, product reviews, and other items where the sentiment of the text may provide useful insights.

In the Main function for your program, find the comment Get sentiment. Then, under this comment, add the code necessary to detect the sentiment of each review document:

C#

C#
 // Get sentiment
 DocumentSentiment sentimentAnalysis = CogClient.AnalyzeSentiment(text);
 Console.WriteLine($"\nSentiment: {sentimentAnalysis.Sentiment}");
Python

Code
 # Get sentiment
 sentimentAnalysis = cog_client.analyze_sentiment(documents=[text])[0]
 print("\nSentiment: {}".format(sentimentAnalysis.sentiment))
Save your changes and return to the integrated terminal for the text-analysis folder, and enter the following command to run the program:

C#

Code
 dotnet run
Python

Code
 python text-analysis.py
Observe the output, noting that the sentiment of the reviews is detected.

Identify key phrases
It can be useful to identify key phrases in a body of text to help determine the main topics that it discusses.

In the Main function for your program, find the comment Get key phrases. Then, under this comment, add the code necessary to detect the key phrases in each review document:

C#

C#
 // Get key phrases
 KeyPhraseCollection phrases = CogClient.ExtractKeyPhrases(text);
 if (phrases.Count > 0)
 {
     Console.WriteLine("\nKey Phrases:");
     foreach(string phrase in phrases)
     {
         Console.WriteLine($"\t{phrase}");
     }
 }
Python

Code
 # Get key phrases
 phrases = cog_client.extract_key_phrases(documents=[text])[0].key_phrases
 if len(phrases) > 0:
     print("\nKey Phrases:")
     for phrase in phrases:
         print('\t{}'.format(phrase))
Save your changes and return to the integrated terminal for the text-analysis folder, and enter the following command to run the program:

C#

Code
 dotnet run
Python

Code
 python text-analysis.py
Observe the output, noting that each document contains key phrases that give some insights into what the review is about.

Extract entities
Often, documents or other bodies of text mention people, places, time periods, or other entities. The text Analytics API can detect multiple categories (and subcategories) of entity in your text.

In the Main function for your program, find the comment Get entities. Then, under this comment, add the code necessary to identify entities that are mentioned in each review:

C#

C#
 // Get entities
 CategorizedEntityCollection entities = CogClient.RecognizeEntities(text);
 if (entities.Count > 0)
 {
     Console.WriteLine("\nEntities:");
     foreach(CategorizedEntity entity in entities)
     {
         Console.WriteLine($"\t{entity.Text} ({entity.Category})");
     }
 }
Python

Code
 # Get entities
 entities = cog_client.recognize_entities(documents=[text])[0].entities
 if len(entities) > 0:
     print("\nEntities")
     for entity in entities:
         print('\t{} ({})'.format(entity.text, entity.category))
Save your changes and return to the integrated terminal for the text-analysis folder, and enter the following command to run the program:

C#

Code
 dotnet run
Python

Code
 python text-analysis.py
Observe the output, noting the entities that have been detected in the text.

Extract linked entities
In addition to categorized entities, the Text Analytics API can detect entities for which there are known links to data sources, such as Wikipedia.

In the Main function for your program, find the comment Get linked entities. Then, under this comment, add the code necessary to identify linked entities that are mentioned in each review:

C#

C#
 // Get linked entities
 LinkedEntityCollection linkedEntities = CogClient.RecognizeLinkedEntities(text);
 if (linkedEntities.Count > 0)
 {
     Console.WriteLine("\nLinks:");
     foreach(LinkedEntity linkedEntity in linkedEntities)
     {
         Console.WriteLine($"\t{linkedEntity.Name} ({linkedEntity.Url})");
     }
 }
Python

Code
 # Get linked entities
 entities = cog_client.recognize_linked_entities(documents=[text])[0].entities
 if len(entities) > 0:
     print("\nLinks")
     for linked_entity in entities:
         print('\t{} ({})'.format(linked_entity.name, linked_entity.url))
Save your changes and return to the integrated terminal for the text-analysis folder, and enter the following command to run the program:

C#

Code
 dotnet run
Python

Code
 python text-analysis.py
Observe the output, noting the linked entities that are identified.
